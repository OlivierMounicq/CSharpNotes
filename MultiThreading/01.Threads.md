## Threads

### 1.GENERALITY


#### 1.1 Processes vs Thread

- Processes are fully isolated from each other
- Threads have just limited degree of isolation
   -> Threads share (heap) memory with other running in the same application

### 2. Threads

#### 2.2 First Thread

##### 2.2.1 No parameter
```cs
public delegate void ThreadStart();
```
=> No returned value

```cs
Thread t = new Thread(WriteY);
t.Start();

static void WriteY(){...}
```


##### 2.2.2 With parameter

```cs
public delegate void ParameterizedThreadStart (object obj);
```
=> Only one parameter

```cs
Thread t = new Thread(WriteY);
t.Start("a string as parameter");

static void WriteY(object param){}
```

#### 2.4 Local state vs shared state

```cs
staic void Main()
{
	new Thread(Go).Start();
	Go;
}

public void Go()
{
	for(int cpt = 0; cpt < 5; cpt++)
	{
		Console.Write("?");
	}	
}
```
The method Go will be instaniate two times in the stack. Each thread has its own memory stack. 
The program will display 10 times the question mark.

#### 2.3 Why to use the multi-threading

- Maintaining a responsive user interface
- Making efficient use of an otherwise blocked CPU
- Parallel programming
- Speculative execution
- Allowing requests to be processed simultaneously (by example: web server)

##### 2.5 Foreground and Background Threads
By default, threads you create explicitly are **_foreground threads_**.
=> Once all foreground threads finish, the application ends, and any background threads still running abruptly terminate.

But, the _pooled_ threads (ie those managing by a thread pool) are background thread.

##### 2.6 Thread Priority

```cs
enum ThreadPriority { Lowest, BelowNormal, Normal, AboveNormal, Highest }
```

_Think carefully before elevating a thread’s priority — it can lead to problems such as resource starvation for other threads._

##### 2.7 The exception Handling

Any _try/catch/finally_ blocks in scope when a thread is created are of no relevance to the thread when it starts executing. Consider the following program:

```cs
public static void Main()
{
  try
  {
    new Thread (Go).Start();
  }
  catch (Exception ex)
  {
    // We'll never get here!
    Console.WriteLine ("Exception!");
  }
}

static void Go() { throw null; }   // Throws a NullReferenceException
```

The try/catch statement in this example is ineffective, and the newly created thread will be encumbered with an unhandled NullReferenceException. This behavior makes sense when you consider that each thread has an independent execution path.



#### 2.8 How Threading works

##### 2.8.1 Thread scheduler

Multithreading is managed internally by a thread scheduler, a function the CLR typically delegates to the operating system.
A thread scheduler ensures all active threads are allocated appropriate execution time, and that threads that are waiting
or blocked (for instance, on an exclusive lock or on user input)  do not consume CPU time.

single-processor computer => a thread scheduler performs time-slicing

multi-processor computer => multithreading is implemented with a mixture of time-slicing and genuine concurrency,
where different threads run code simultaneously on different CPUs

##### 2.8.2 Thread pooling

###### 2.8.2.1 Generality

Whenever you start a thread, a few hundred microseconds are spent organizing such things as a fresh private local variable stack. Each thread also consumes (by default) around 1 MB of memory. The _**thread pool**_ cuts these overheads by sharing and recycling threads, allowing multithreading to be applied at a very granular level without a performance penalty. This is useful when leveraging multicore processors to execute computationally intensive code in parallel in “divide-and-conquer” style.

The thread pool also keeps a lid on the total number of worker threads it will run simultaneously. Too many active threads throttle the operating system with administrative burden and render CPU caches ineffective. Once a limit is reached, jobs queue up and start only when another finishes

=> The thread pool uses a hill-climbing algorithm to manage the different threads.

###### 2.8.2.1.1 In the engine


###### 2.8.2.1.2 The conditions to optimize the thread pool

The thread pool strategy (implemented in the CLR) works best if the following condtions are met:
- work items are short running (<250 ms, ideally <100ms)
- the thread spend the most of their time blocked do not dominate the pool

The _oversubscription_ is the devil.


###### 2.8.2.2 Thread pool without TPL (prior 4.0)

The tasks didn't exist prior version 4.0, the only way to call the thread pool was to call 

```cs
ThreadPool.QueueUserWorkItem

public static bool QueueUserWorkItem(
	WaitCallback callBack
)
```



###### 2.8.2.3 Thread pool with the TPL

To use the thread pool, you can call __Task.Run__

```cs
Task.Run(() => Console.WriteLine("Hello the thread pool!"));
```


##### 2.8.3.4 The thread pool inconveninces

- You can not set the name of a pooled thread
- the pooled threads are __always__ _background threads_.
- blocking pooled threads can degrade performance

To know if the thread is a pooled thread : Thread.CurrentThread.IsThreadPoolThread


#### 2.9 Some misunderstandings

##### 2.9.1 The captured variables

By example, this code

```cs
for (int i = 0; i < 10; i++)
  new Thread (() => Console.Write (i)).Start();
```

won't return 012356789 but the returned output could be this one
0223557799

===> BEWARE : the captured variables => the problem is that the _i_ variable refers to the same memory location throughout the loop's lifetime. Therefore, each thread calls Console.Write on a variable whose the value may change as it running.

To avoid this problem, a solution is to use the temp variable : 

```cs
for (int i = 0; i < 10; i++)
{
  int temp = i;
  new Thread (() => Console.Write (temp)).Start();
}
```

Another error is:
```cs
string text = "t1";
Thread t1 = new Thread ( () => Console.WriteLine (text) );
 
text = "t2";
Thread t2 = new Thread ( () => Console.WriteLine (text) );
 
t1.Start();
t2.Start();
```

And the output will be:
- t1
- t2

